use std::cell::RefCell;
use std::collections::HashMap;
use std::collections::VecDeque;
use std::fs;
use std::ops::Range;
use std::path::PathBuf;

use cake_lex::DFAScanner;
use cake_lex::LexemeSet;
use lexeme_sets::c_lexemes::CLexemes;
use lexeme_sets::c_preprocessor::CPreprocessor;
use thiserror::Error;

use crate::platform::Platform;

// autogenerated lexeme sets
pub mod lexeme_sets;

// TODO: think about what interface should be for backtracking due to
// parsing troubles
pub trait TokenStream<T: LexemeSet> {
    fn eat(&mut self, lexeme: T) -> bool;
    fn peek(&mut self) -> Option<(T, &str, usize)>;
    fn peekn(&mut self, n: usize) -> Option<(T, &str, usize)>;
    fn advance(&mut self) -> Option<(T, &str, usize)>;

    fn rollback(&mut self, target: usize);
    fn get_location(&self) -> usize;
}

// TODO: processed token stream to implement preprocessor
// don't think you have to do a separate pass for preprocessing
const BUFFER_SIZE: usize = 10;
pub struct RawTokenStream<'a, T>
where
    T: LexemeSet,
{
    cursor: usize,
    scanner: DFAScanner,
    source: &'a [u8],

    buffer: VecDeque<(T, &'a str, usize)>,
}

impl<'a, T: LexemeSet> RawTokenStream<'a, T> {
    pub fn new(scanner: DFAScanner, source: &'a [u8]) -> RawTokenStream<'a, T> {
        let retval = RawTokenStream {
            cursor: 0,
            scanner,
            source,

            buffer: VecDeque::new(),
        };

        retval
    }

    fn refill_buffer(&mut self) {
        self.refill_buffer_to_size(BUFFER_SIZE);
    }

    fn refill_buffer_to_size(&mut self, size: usize) {
        while self.buffer.len() < size {
            let (lexeme, action, next_cursor) = self.scanner.next_word(self.source, self.cursor);

            if action == -1 {
                break;
            }
            // if action as u32 == CLexemes::Whitespace.to_id() {
            //     self.cursor = next_cursor;
            //     continue;
            // }
            let l = T::from_id(action as u32).expect("invalid action (is the scanner compatible?)");
            self.buffer.push_back((l, lexeme, self.cursor));
            self.cursor = next_cursor;
        }
    }
}

// TODO: optimize this
impl<'a, T> TokenStream<T> for RawTokenStream<'a, T>
where
    T: LexemeSet,
{
    fn eat(&mut self, expected_lexeme: T) -> bool {
        self.refill_buffer();
        let matched = match self.buffer.pop_front() {
            Some((lexeme, _, _)) if lexeme == expected_lexeme => true,
            _ => false,
        };

        matched
    }

    fn peek(&mut self) -> Option<(T, &str, usize)> {
        self.refill_buffer();
        self.buffer.front().copied()
    }

    fn advance(&mut self) -> Option<(T, &str, usize)> {
        self.refill_buffer();
        let old_memo = self.buffer.pop_front();
        old_memo
    }

    fn rollback(&mut self, target: usize) {
        self.cursor = target;
        self.buffer.clear();
    }

    fn get_location(&self) -> usize {
        self.cursor
    }

    fn peekn(&mut self, n: usize) -> Option<(T, &str, usize)> {
        self.refill_buffer_to_size(n + 1);
        self.buffer.get(n).copied()
    }
}

// specialized implementation for C lexemes
// implements preprocessing logic
struct Preprocessor {
    preprocess_scanner: DFAScanner,
    main_scanner: DFAScanner,
    platform: Platform,

    sources_map: HashMap<PathBuf, SourceFileDescriptor>,
    sources: Vec<Box<str>>, // Box<str> is preferable, since no need to mutate source files (?)

    cursor_stack: Vec<SourceCursor>,
    macros: HashMap<String, PreprocessorMacro>,

    conditional_stack: Vec<ConditionalState>,
    pp_token_line_buffer: VecDeque<PreprocessorToken>,
    macro_invocation: Option<FunctionMacroInvocation>,
    str_literal_concat_buffer: Option<StringLiteral>,
    clexeme_buffer: VecDeque<CToken>,
}

// invariant: span always refers to current source
// should be upheld as long as we only get_line once pp_token_buffer is empty
#[derive(Clone, Copy, Debug)]
struct PreprocessorToken {
    token: CPreprocessor,
    span: (usize, usize),
    whitespace_left: bool,
}

#[derive(Clone, Debug)]
enum CToken {
    FromSource {
        token: CLexemes,
        span: (usize, usize),
    },
    // this is for concatenated tokens (## operator) and for string literal concatenation (translation phase 6)
    Owned {
        token: CLexemes,
        string: String,
        span: (usize, usize),
    },
}

#[derive(Clone, Copy, Debug, PartialEq, Eq)]
enum ConditionalState {
    NoneTaken,
    Active,
    SomeTaken,
}

struct FunctionMacroInvocation {
    name: PreprocessorToken,
    arguments: Vec<Vec<PreprocessorToken>>,
}

enum StringLiteral {
    Single(usize, usize),
    Concatenated(String, usize, usize),
}

impl FunctionMacroInvocation {
    fn add_pp_token(&mut self, pp_token: PreprocessorToken) -> bool {
        todo!()
    }
}

struct SourceFileDescriptor {
    // header guard optimization - #pragma once
    header_guard: bool,
    source_idx: usize,
}

#[derive(Debug, Clone)]
struct SourceCursor {
    filepath: PathBuf,
    file_idx: usize,
    cursor: usize,
    line: usize,
}

enum PreprocessorMacro {
    ObjectMacro,
    FunctionMacro,
}

#[derive(Debug, Error)]
enum ScannerError {}

impl Preprocessor {
    pub fn new(file: PathBuf, contents: String, platform: Platform) -> Self {
        let preprocess_scanner = DFAScanner::new(CPreprocessor::load_table());
        let main_scanner = DFAScanner::new(CLexemes::load_table());

        let sources = vec![contents.into_boxed_str()];
        let mut sources_map = HashMap::new();
        sources_map.insert(
            file.clone(),
            SourceFileDescriptor {
                header_guard: false,
                source_idx: 0,
            },
        );

        Self {
            preprocess_scanner,
            main_scanner,
            platform,

            sources_map,
            sources,
            cursor_stack: vec![SourceCursor {
                filepath: file,
                file_idx: 0,
                cursor: 0,
                line: 1,
            }],

            macros: HashMap::new(),
            pp_token_line_buffer: VecDeque::new(),
            macro_invocation: None,
            clexeme_buffer: VecDeque::new(),
            str_literal_concat_buffer: None,
            conditional_stack: Vec::new(),
        }
    }

    fn include_file(&mut self, file: &str, normal: bool) {
        // 1. resolve path
        let file_path = if normal {
            self.platform.resolve_normal_include_path(file)
        } else {
            self.platform.resolve_system_include_path(file)
        }
        .expect("failed to resolve include");

        // 2. check for include guard / if file is already open
        if let Some(src_file) = self.sources_map.get(&file_path) {
            if src_file.header_guard {
                return;
            } else {
                self.cursor_stack.push(SourceCursor {
                    filepath: file_path,
                    file_idx: src_file.source_idx,
                    cursor: 0,
                    line: 1,
                });

                return;
            }
        }

        // 3. read file
        let contents = fs::read_to_string(&file_path).expect("err while opening file");

        // 4. update cursor stack and opened src file map
        let idx = self.sources.len();
        self.sources.push(contents.into_boxed_str());
        let src_descriptor = SourceFileDescriptor {
            header_guard: false,
            source_idx: idx,
        };
        self.sources_map.insert(file_path.clone(), src_descriptor);
        self.cursor_stack.push(SourceCursor {
            filepath: file_path,
            file_idx: idx,
            cursor: 0,
            line: 1,
        });
    }

    fn get_current_src_str(&self) -> &str {
        self.sources[self.current_cursor().file_idx].as_ref()
    }

    fn get_remaining_src_str(&self) -> &str {
        let current_src_str = self.get_current_src_str();
        &current_src_str[self.current_cursor().cursor..]
    }

    // invariant: cursor stack must never be fully empty until compiler is finished
    fn current_cursor(&self) -> &SourceCursor {
        self.cursor_stack.last().unwrap()
    }

    fn current_cursor_mut(&mut self) -> &mut SourceCursor {
        self.cursor_stack.last_mut().unwrap()
    }

    fn get_text(&self, span: (usize, usize)) -> &str {
        &self.get_current_src_str()[span.0..span.1]
    }

    // line-by-line processing could lead to super pathological cases (e.g. gigantic single line macros)
    // or if someone decides to put their entire source file in one big line
    // but this is much simpler
    fn process_line(&mut self) -> bool {
        // if current file is empty, pop cursor stack
        let mut remaining_src_str = self.get_remaining_src_str();
        while remaining_src_str.is_empty() {
            match self.cursor_stack.pop() {
                Some(src_cursor) => {
                    if self.cursor_stack.is_empty() {
                        self.cursor_stack.push(src_cursor);
                        return false;
                    } else {
                        remaining_src_str = self.get_remaining_src_str();
                    }
                }
                None => unreachable!("cursor stack should always be nonempty"),
            }
        }

        let mut prev_char: char = '\n';
        let mut physical_lines = 0;
        let logical_line_break = remaining_src_str
            .find(|c| {
                if prev_char != '\\' && c == '\n' {
                    physical_lines += 1;
                    true
                } else {
                    physical_lines += if c == '\n' { 1 } else { 0 };
                    prev_char = c;
                    false
                }
            })
            // include newline within line (if this line doesn't include final line of file)
            .map(|p| p + '\n'.len_utf8());

        let old_cursor = self.current_cursor().cursor;
        if let Some(line_break) = logical_line_break {
            self.current_cursor_mut().line += physical_lines;
            self.current_cursor_mut().cursor = line_break;
        } else {
            self.current_cursor_mut().line += physical_lines;
            self.current_cursor_mut().cursor = self.get_current_src_str().len();
        }

        let mut cursor = old_cursor;
        let mut prev_whitespace = false;
        loop {
            let src_str = self.get_current_src_str();
            let (_, action, next_cursor) = self
                .preprocess_scanner
                .next_word(src_str.as_bytes(), cursor);

            if action == -1 {
                break;
            }

            let token = CPreprocessor::from_id(action as u32)
                .expect("C preprocessor DFA should be infallible");

            if let CPreprocessor::Newline = token {
                break;
            }
            if let CPreprocessor::Splice = token {
                continue;
            }
            if let CPreprocessor::Whitespace = token {
                prev_whitespace = true;
                continue;
            }

            let preprocessor_token = PreprocessorToken {
                token,
                span: (cursor, next_cursor),
                whitespace_left: prev_whitespace,
            };

            prev_whitespace = false;
            cursor = next_cursor;
            self.pp_token_line_buffer.push_back(preprocessor_token);
        }
        return true;
    }

    // precondition: directive token is already processed, pp_token_line_buffer
    // only contains contents after # <directive> (w/ no leading whitespace)
    fn preprocessor_directive(&mut self, directive_token: PreprocessorToken) {
        #[derive(Clone, Copy, PartialEq, Eq)]
        enum DirectiveType {
            If,
            Ifdef,
            Ifndef,
            Elif,
            Else,
            Endif,
            Include,
            Define,
            Undef,
            Line,
            Error,
            Pragma,
        }

        let directive_type = match self.get_text(directive_token.span) {
            "if" => DirectiveType::If,
            "ifdef" => DirectiveType::Ifdef,
            "ifndef" => DirectiveType::Ifndef,
            "elif" => DirectiveType::Elif,
            "else" => DirectiveType::Else,
            "endif" => DirectiveType::Endif,
            "include" => DirectiveType::Include,
            "define" => DirectiveType::Define,
            "undef" => DirectiveType::Undef,
            "line" => DirectiveType::Line,
            "error" => DirectiveType::Error,
            "pragma" => DirectiveType::Pragma,
            other => {
                eprintln!("warning: unrecognized directive {}", other);
                self.pp_token_line_buffer.clear();
                return;
            }
        };

        let mut pp_iter = self.pp_token_line_buffer.iter();
        match directive_type {
            DirectiveType::If => todo!(),
            x @ (DirectiveType::Ifdef | DirectiveType::Ifndef) => {
                match pp_iter.next() {
                    Some(PreprocessorToken {
                        token: CPreprocessor::Identifier,
                        span,
                        ..
                    }) => {
                        let macro_name = self.get_text(*span);
                        match (x, self.macros.contains_key(macro_name)) {
                            (DirectiveType::Ifdef, true) | (DirectiveType::Ifndef, false) => {
                                self.conditional_stack.push(ConditionalState::Active);
                            }
                            (DirectiveType::Ifdef, false) | (DirectiveType::Ifndef, true) => {
                                self.conditional_stack.push(ConditionalState::NoneTaken);
                            }
                            _ => unreachable!(),
                        };
                    }
                    None | _ => {
                        eprintln!("#if(n)def must be followed by an identifier");
                        todo!()
                    }
                }

                if pp_iter.len() != 0 {
                    eprintln!("unexpected token after #if(n)def");
                    todo!()
                }
            }

            DirectiveType::Elif => todo!(),
            DirectiveType::Else => {
                if pp_iter.len() != 0 {
                    eprintln!("warning: unexpected token after #else");
                    todo!()
                }

                match self.conditional_stack.last_mut() {
                    Some(inner) => {
                        *inner = match *inner {
                            ConditionalState::NoneTaken => ConditionalState::Active,
                            ConditionalState::Active | ConditionalState::SomeTaken => {
                                ConditionalState::SomeTaken
                            }
                        }
                    }
                    None => {
                        eprintln!("warning: unexpected #else");
                        todo!()
                    }
                }
            }
            DirectiveType::Endif => {
                if pp_iter.len() != 0 {
                    eprintln!("warning: unexpected token after #endif");
                    todo!()
                }

                if self.conditional_stack.len() == 0 {
                    eprintln!("warning: unexpected #endif");
                    todo!()
                }

                self.conditional_stack.pop();
            }
            DirectiveType::Include => {
                let file = pp_iter.next();
                match file {
                    Some(PreprocessorToken {
                        token: CPreprocessor::StringLiteral,
                        span,
                        ..
                    }) if pp_iter.len() == 0 => {
                        // "normal" (quote) include
                        let file = self.get_text(*span).trim_matches('"').to_string();
                        self.include_file(&file, true);
                        return;
                    }
                    Some(PreprocessorToken {
                        token: CPreprocessor::OtherPunctuator,
                        span,
                        ..
                    }) if self.get_text(*span) == "<" => {
                        let langle = span.0;
                        let rangle = loop {
                            if let Some(pp_token) = pp_iter.next() {
                                if pp_token.token == CPreprocessor::OtherPunctuator
                                    && self.get_text(pp_token.span) == ">"
                                {
                                    break Some(pp_token.span.1);
                                }
                            } else {
                                break None;
                            }
                        };

                        // fall through to macro-replacement case if no matching '>' or still have more tokens
                        if let Some(rangle) = rangle {
                            if pp_iter.len() == 0 {
                                let file = self
                                    .get_text((langle, rangle))
                                    .trim_matches(['<', '>'])
                                    .to_string();
                                self.include_file(&file, false);
                                return;
                            }
                        }
                    }
                    Some(_) => {
                        // fall through to macro replacement case
                    }
                    None => {
                        eprintln!("bad include directive");
                        todo!()
                    }
                }

                todo!("macro replacement case")
            }
            DirectiveType::Define => {}
            DirectiveType::Undef => {
                let macro_name = pp_iter.next();
                if let Some(name) = macro_name {
                    let macro_name = self.get_text(name.span);
                    self.macros.remove(&macro_name.to_string()); // borrowck does not like
                } else {
                    todo!()
                }

                if pp_iter.next().is_some() {
                    eprintln!("Unexpected token");
                    todo!()
                }
            }
            DirectiveType::Line => {
                todo!("line directive")
            }
            DirectiveType::Error => {
                let error_pp_tokens: Vec<_> = pp_iter.map(|x| self.get_text(x.span)).collect();

                eprintln!("error: {}", error_pp_tokens.join(" "));
            }
            DirectiveType::Pragma => {
                todo!("pragma directive")
            }
        }

        self.pp_token_line_buffer.clear();
    }

    fn convert_pp_token_to_clexeme(&mut self, pp_token: PreprocessorToken) {
        let text = self.get_text(pp_token.span);
        let (_, action, end_cursor) = self.main_scanner.next_word(text.as_bytes(), 0);
        if action == -1 || end_cursor != (pp_token.span.1 - pp_token.span.0) {
            todo!("failed to convert preprocessing token to clexeme");
        }

        let clexeme = CLexemes::from_id(action as u32)
            .expect("failed to convert preprocessing token to clexeme");

        match (clexeme, &mut self.str_literal_concat_buffer) {
            (CLexemes::StringConst, Some(StringLiteral::Single(left, right))) => {
                let span = (*left, *right);
                let mut text = self.get_text(span).to_string();
                let second_span = (pp_token.span.0 + 1, pp_token.span.1 - 1);
                let second_text = self.get_text(second_span);
                text.push_str(second_text);
                self.str_literal_concat_buffer =
                    Some(StringLiteral::Concatenated(text, span.0, second_span.1));
            }
            (CLexemes::StringConst, Some(StringLiteral::Concatenated(s, left, _right))) => {
                let mut owned = std::mem::take(s);
                let left = *left;
                let new_span = (pp_token.span.0 + 1, pp_token.span.1 - 1);
                let new_text = self.get_text(new_span);
                owned.push_str(new_text);
                self.str_literal_concat_buffer =
                    Some(StringLiteral::Concatenated(owned, left, new_span.1));
            }
            (CLexemes::StringConst, None) => {
                self.str_literal_concat_buffer = Some(StringLiteral::Single(
                    pp_token.span.0 + 1,
                    pp_token.span.1 - 1,
                )) // exclude quotes
            }
            (other, Some(StringLiteral::Single(left, right))) => {
                self.clexeme_buffer.push_back(CToken::FromSource {
                    token: CLexemes::StringConst,
                    span: (*left, *right),
                });
                std::mem::take(&mut self.str_literal_concat_buffer);
                self.clexeme_buffer.push_back(CToken::FromSource {
                    token: other,
                    span: pp_token.span,
                });
            }
            (other, Some(StringLiteral::Concatenated(concat, left, right))) => {
                self.clexeme_buffer.push_back(CToken::Owned {
                    token: CLexemes::StringConst,
                    string: std::mem::take(concat),
                    span: (*left, *right),
                });
                std::mem::take(&mut self.str_literal_concat_buffer);
                self.clexeme_buffer.push_back(CToken::FromSource {
                    token: other,
                    span: pp_token.span,
                });
            }
            (other, None) => {
                self.clexeme_buffer.push_back(CToken::FromSource {
                    token: other,
                    span: pp_token.span,
                });
            }
        }
    }

    fn add_token_to_macro_invocation(&mut self, pp_token: PreprocessorToken) {
        self.macro_invocation
            .as_mut()
            .expect("macro invocation must be non-null before calling this")
            .add_pp_token(pp_token);
    }

    // precondition: pp_token_line_buffer contains all preprocessing tokens (excluding splices and final newline) from a single logical line
    fn convert_line_to_clexemes(&mut self) {
        // check for preprocessing directive
        if self.pp_token_line_buffer.len() >= 2
            && self.pp_token_line_buffer[0].token == CPreprocessor::Hash
            && self.pp_token_line_buffer[1].token == CPreprocessor::Identifier
        {
            self.pp_token_line_buffer.pop_front().unwrap();
            let directive_token = self.pp_token_line_buffer.pop_front().unwrap();
            self.preprocessor_directive(directive_token);
        } else {
            // not a preprocessing directive; attempt macro substitution / conversion to CLexemes
            for pp_token in std::mem::take(&mut self.pp_token_line_buffer) {
                // handle function macro arguments
                if let Some(macro_invocation) = &self.macro_invocation {
                    if macro_invocation.arguments.len() == 0 {
                        // check for lparen, and also check if the macro still exists (could've been #undef'd)
                        let macro_name = self.get_text(macro_invocation.name.span);
                        if pp_token.token == CPreprocessor::LParen
                            && self.macros.contains_key(macro_name)
                        {
                            self.add_token_to_macro_invocation(pp_token);
                            continue;
                        } else {
                            let empty_macro_invocation =
                                std::mem::take(&mut self.macro_invocation).unwrap();

                            self.convert_pp_token_to_clexeme(empty_macro_invocation.name);
                            self.convert_pp_token_to_clexeme(pp_token);
                            continue;
                        }
                    } else {
                        self.add_token_to_macro_invocation(pp_token);
                        continue;
                    }
                }

                // handle macro substitution
                let text = self.get_text(pp_token.span);
                if let Some(pp_macro) = self.macros.get(text) {
                    match pp_macro {
                        PreprocessorMacro::ObjectMacro => todo!("object macro case"),
                        PreprocessorMacro::FunctionMacro => {
                            self.macro_invocation = Some(FunctionMacroInvocation {
                                name: pp_token,
                                arguments: Default::default(),
                            });
                            continue;
                        }
                    }
                }

                // handle "normal" text
                self.convert_pp_token_to_clexeme(pp_token);
            }
        }
    }
}

impl TokenStream<CLexemes> for Preprocessor {
    fn eat(&mut self, lexeme: CLexemes) -> bool {
        todo!()
    }

    fn peek(&mut self) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn peekn(&mut self, n: usize) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn advance(&mut self) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn rollback(&mut self, target: usize) {
        todo!()
    }

    fn get_location(&self) -> usize {
        todo!()
    }
}
