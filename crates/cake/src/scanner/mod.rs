use std::cell::RefCell;
use std::collections::HashMap;
use std::collections::VecDeque;
use std::fs;
use std::ops::Range;
use std::path::PathBuf;

use cake_lex::DFAScanner;
use cake_lex::LexemeSet;
use lexeme_sets::c_lexemes::CLexemes;
use lexeme_sets::c_preprocessor::CPreprocessor;

// autogenerated lexeme sets
pub mod lexeme_sets;

// TODO: think about what interface should be for backtracking due to
// parsing troubles
pub trait TokenStream<T: LexemeSet> {
    fn eat(&mut self, lexeme: T) -> bool;
    fn peek(&mut self) -> Option<(T, &str, usize)>;
    fn peekn(&mut self, n: usize) -> Option<(T, &str, usize)>;
    fn advance(&mut self) -> Option<(T, &str, usize)>;

    fn rollback(&mut self, target: usize);
    fn get_location(&self) -> usize;
}

// TODO: processed token stream to implement preprocessor
// don't think you have to do a separate pass for preprocessing
const BUFFER_SIZE: usize = 10;
pub struct RawTokenStream<'a, T>
where
    T: LexemeSet,
{
    cursor: usize,
    scanner: DFAScanner,
    source: &'a [u8],

    buffer: VecDeque<(T, &'a str, usize)>,
}

impl<'a, T: LexemeSet> RawTokenStream<'a, T> {
    pub fn new(scanner: DFAScanner, source: &'a [u8]) -> RawTokenStream<'a, T> {
        let retval = RawTokenStream {
            cursor: 0,
            scanner,
            source,

            buffer: VecDeque::new(),
        };

        retval
    }

    fn refill_buffer(&mut self) {
        self.refill_buffer_to_size(BUFFER_SIZE);
    }

    fn refill_buffer_to_size(&mut self, size: usize) {
        while self.buffer.len() < size {
            let (lexeme, action, next_cursor) = self.scanner.next_word(self.source, self.cursor);

            if action == -1 {
                break;
            }
            // if action as u32 == CLexemes::Whitespace.to_id() {
            //     self.cursor = next_cursor;
            //     continue;
            // }
            let l = T::from_id(action as u32).expect("invalid action (is the scanner compatible?)");
            self.buffer.push_back((l, lexeme, self.cursor));
            self.cursor = next_cursor;
        }
    }
}

// TODO: optimize this
impl<'a, T> TokenStream<T> for RawTokenStream<'a, T>
where
    T: LexemeSet,
{
    fn eat(&mut self, expected_lexeme: T) -> bool {
        self.refill_buffer();
        let matched = match self.buffer.pop_front() {
            Some((lexeme, _, _)) if lexeme == expected_lexeme => true,
            _ => false,
        };

        matched
    }

    fn peek(&mut self) -> Option<(T, &str, usize)> {
        self.refill_buffer();
        self.buffer.front().copied()
    }

    fn advance(&mut self) -> Option<(T, &str, usize)> {
        self.refill_buffer();
        let old_memo = self.buffer.pop_front();
        old_memo
    }

    fn rollback(&mut self, target: usize) {
        self.cursor = target;
        self.buffer.clear();
    }

    fn get_location(&self) -> usize {
        self.cursor
    }

    fn peekn(&mut self, n: usize) -> Option<(T, &str, usize)> {
        self.refill_buffer_to_size(n + 1);
        self.buffer.get(n).copied()
    }
}

// specialized implementation for C lexemes
// implements preprocessing logic
struct Preprocessor {
    preprocess_scanner: DFAScanner,
    main_scanner: DFAScanner,

    sources_map: HashMap<PathBuf, SourceFileDescriptor>,
    sources: Vec<Box<str>>, // Box<str> is preferable, since no need to mutate source files (?)

    cursor_stack: Vec<SourceCursor>,
    macros: HashMap<String, PreprocessorMacro>,

    conditional_stack: Vec<ConditionalState>,
    pp_token_line_buffer: VecDeque<PreprocessorToken>,
    clexeme_buffer: VecDeque<CToken>,
}

// invariant: span always refers to current source
// should be upheld as long as we only get_line once pp_token_buffer is empty
#[derive(Clone, Copy, Debug)]
struct PreprocessorToken {
    token: CPreprocessor,
    span: (usize, usize),
}

struct CToken {
    token: CLexemes,
    span: (usize, usize),
}

#[derive(Clone, Copy, Debug, PartialEq, Eq)]
enum ConditionalState {
    NoneTaken,
    Active,
    SomeTaken,
}

struct FunctionMacroInvocation {}

struct SourceFileDescriptor {
    // header guard optimization - #pragma once
    header_guard: bool,
    source_idx: usize,
}

#[derive(Debug, Clone)]
struct SourceCursor {
    filepath: PathBuf,
    file_idx: usize,
    cursor: usize,
    line: usize,
}

enum PreprocessorMacro {
    ObjectMacro,
    FunctionMacro,
}

impl Preprocessor {
    pub fn new(file: PathBuf, contents: String) -> Self {
        let preprocess_scanner = DFAScanner::new(CPreprocessor::load_table());
        let main_scanner = DFAScanner::new(CLexemes::load_table());

        let sources = vec![contents.into_boxed_str()];
        let mut sources_map = HashMap::new();
        sources_map.insert(
            file.clone(),
            SourceFileDescriptor {
                header_guard: false,
                source_idx: 0,
            },
        );

        Self {
            preprocess_scanner,
            main_scanner,
            sources_map,
            sources,
            cursor_stack: vec![SourceCursor {
                filepath: file,
                file_idx: 0,
                cursor: 0,
                line: 1,
            }],

            macros: HashMap::new(),
            pp_token_line_buffer: VecDeque::new(),
            clexeme_buffer: VecDeque::new(),
            conditional_stack: Vec::new(),
        }
    }

    fn include_file(&mut self, path: PathBuf) {
        // 1. check for include guard / if file is already open
        if let Some(src_file) = self.sources_map.get(&path) {
            if src_file.header_guard {
                return;
            } else {
                self.cursor_stack.push(SourceCursor {
                    filepath: path,
                    file_idx: src_file.source_idx,
                    cursor: 0,
                    line: 1,
                });

                return;
            }
        }

        // 2. read file
        let contents = fs::read_to_string(&path).expect("err while opening file");

        // 3. update cursor stack and opened src file map
        let idx = self.sources.len();
        self.sources.push(contents.into_boxed_str());
        let src_descriptor = SourceFileDescriptor {
            header_guard: false,
            source_idx: idx,
        };
        self.sources_map.insert(path.clone(), src_descriptor);
        self.cursor_stack.push(SourceCursor {
            filepath: path,
            file_idx: idx,
            cursor: 0,
            line: 1,
        });
    }

    fn get_current_src_str(&self) -> &str {
        self.sources[self.current_cursor().file_idx].as_ref()
    }

    fn get_remaining_src_str(&self) -> &str {
        let current_src_str = self.get_current_src_str();
        &current_src_str[self.current_cursor().cursor..]
    }

    // invariant: cursor stack must never be fully empty until compiler is finished
    fn current_cursor(&self) -> &SourceCursor {
        self.cursor_stack.last().unwrap()
    }

    fn current_cursor_mut(&mut self) -> &mut SourceCursor {
        self.cursor_stack.last_mut().unwrap()
    }

    fn get_text(&self, span: (usize, usize)) -> &str {
        &self.get_current_src_str()[span.0..span.1]
    }

    // line-by-line processing could lead to super pathological cases (e.g. gigantic single line macros)
    // or if someone decides to put their entire source file in one big line
    // but this is much simpler
    fn process_line(&mut self) -> bool {
        // if current file is empty, pop cursor stack
        let mut remaining_src_str = self.get_remaining_src_str();
        while remaining_src_str.is_empty() {
            match self.cursor_stack.pop() {
                Some(src_cursor) => {
                    if self.cursor_stack.is_empty() {
                        self.cursor_stack.push(src_cursor);
                        return false;
                    } else {
                        remaining_src_str = self.get_remaining_src_str();
                    }
                }
                None => unreachable!("cursor stack should always be nonempty"),
            }
        }

        let mut prev_char: char = '\n';
        let mut physical_lines = 0;
        let logical_line_break = remaining_src_str
            .find(|c| {
                if prev_char != '\\' && c == '\n' {
                    physical_lines += 1;
                    true
                } else {
                    physical_lines += if c == '\n' { 1 } else { 0 };
                    prev_char = c;
                    false
                }
            })
            // include newline within line (if this line doesn't include final line of file)
            .map(|p| p + '\n'.len_utf8());

        let old_cursor = self.current_cursor().cursor;
        if let Some(line_break) = logical_line_break {
            self.current_cursor_mut().line += physical_lines;
            self.current_cursor_mut().cursor = line_break;
        } else {
            self.current_cursor_mut().line += physical_lines;
            self.current_cursor_mut().cursor = self.get_current_src_str().len();
        }

        let mut cursor = old_cursor;
        loop {
            let src_str = self.get_current_src_str();
            let (_, action, next_cursor) = self
                .preprocess_scanner
                .next_word(src_str.as_bytes(), cursor);

            if action == -1 {
                break;
            }

            let token = CPreprocessor::from_id(action as u32)
                .expect("C preprocessor DFA should be infallible");

            if let CPreprocessor::Newline = token {
                break;
            }
            if let CPreprocessor::Splice = token {
                continue;
            }

            let preprocessor_token = PreprocessorToken {
                token,
                span: (cursor, next_cursor),
            };

            cursor = next_cursor;
            self.pp_token_line_buffer.push_back(preprocessor_token);
        }
        return true;
    }

    // precondition: directive token is already processed, pp_token_line_buffer
    // only contains contents after # <directive> (w/ no leading whitespace)
    fn preprocessor_directive(&mut self, directive_token: PreprocessorToken) {
        #[derive(Clone, Copy, PartialEq, Eq)]
        enum DirectiveType {
            If,
            Ifdef,
            Ifndef,
            Elif,
            Else,
            Endif,
            Include,
            Define,
            Undef,
            Line,
            Error,
            Pragma,
        }

        let directive_type = match self.get_text(directive_token.span) {
            "if" => DirectiveType::If,
            "ifdef" => DirectiveType::Ifdef,
            "ifndef" => DirectiveType::Ifndef,
            "elif" => DirectiveType::Elif,
            "else" => DirectiveType::Else,
            "endif" => DirectiveType::Endif,
            "include" => DirectiveType::Include,
            "define" => DirectiveType::Define,
            "undef" => DirectiveType::Undef,
            "line" => DirectiveType::Line,
            "error" => DirectiveType::Error,
            "pragma" => DirectiveType::Pragma,
            other => {
                eprintln!("warning: unrecognized directive {}", other);
                self.pp_token_line_buffer.clear();
                return;
            }
        };

        if directive_type == DirectiveType::Define {
            // special case - need to distinguish
            // #define fn(a, b)
            // #define fn (a, b)
            // so whitespace matters
            todo!()
        }

        let mut no_whitespace = self.pp_token_line_buffer.iter();
        match directive_type {
            DirectiveType::If => todo!(),
            x @ (DirectiveType::Ifdef | DirectiveType::Ifndef) => {
                match no_whitespace.next() {
                    Some(PreprocessorToken {
                        token: CPreprocessor::Identifier,
                        span,
                    }) => {
                        let macro_name = self.get_text(*span);
                        let state = match (x, self.macros.contains_key(macro_name)) {
                            (DirectiveType::Ifdef, true) | (DirectiveType::Ifndef, false) => {
                                self.conditional_stack.push(ConditionalState::Active);
                            }
                            (DirectiveType::Ifdef, false) | (DirectiveType::Ifndef, true) => {
                                self.conditional_stack.push(ConditionalState::NoneTaken);
                            }
                            _ => unreachable!(),
                        };
                    }
                    None | _ => {
                        eprintln!("#if(n)def must be followed by an identifier");
                        todo!()
                    }
                }

                if no_whitespace.len() != 0 {
                    eprintln!("unexpected token after #if(n)def");
                    todo!()
                }
            }

            DirectiveType::Elif => todo!(),
            DirectiveType::Else => {
                if no_whitespace.len() != 0 {
                    eprintln!("warning: unexpected token after #else");
                    todo!()
                }

                match self.conditional_stack.last_mut() {
                    Some(inner) => {
                        *inner = match *inner {
                            ConditionalState::NoneTaken => ConditionalState::Active,
                            ConditionalState::Active | ConditionalState::SomeTaken => {
                                ConditionalState::SomeTaken
                            }
                        }
                    }
                    None => {
                        eprintln!("warning: unexpected #else");
                        todo!()
                    }
                }
            }
            DirectiveType::Endif => {
                if no_whitespace.len() != 0 {
                    eprintln!("warning: unexpected token after #endif");
                    todo!()
                }

                if self.conditional_stack.len() == 0 {
                    eprintln!("warning: unexpected #endif");
                    todo!()
                }

                self.conditional_stack.pop();
            }
            DirectiveType::Include => {
                let mut no_whitespace_copy = no_whitespace.clone();
                let file = no_whitespace_copy.next();
                match file {
                    Some(PreprocessorToken {
                        token: CPreprocessor::StringLiteral,
                        span,
                    }) => {
                        // "normal" include
                        todo!()
                    }
                    Some(PreprocessorToken {
                        token: CPreprocessor::OtherPunctuator,
                        span,
                    }) if self.get_text(*span) == "<" => {
                        todo!()
                    }
                    Some(_) => {
                        todo!()
                    }
                    None => {
                        eprintln!("bad include directive");
                        todo!()
                    }
                }
            }
            DirectiveType::Define => unreachable!(),
            DirectiveType::Undef => {
                let macro_name = no_whitespace.next();
                if let Some(name) = macro_name {
                    let macro_name = self.get_text(name.span);
                    self.macros.remove(&macro_name.to_string()); // borrowck does not like
                } else {
                    todo!()
                }

                if no_whitespace.next().is_some() {
                    eprintln!("Unexpected token");
                    todo!()
                }
            }
            DirectiveType::Line => todo!(),
            DirectiveType::Error => {
                let error_pp_tokens: Vec<_> = no_whitespace
                    .filter(|x| x.token != CPreprocessor::Whitespace)
                    .map(|x| self.get_text(x.span))
                    .collect();

                eprintln!("error: {}", error_pp_tokens.join(" "));
            }
            DirectiveType::Pragma => {
                todo!()
            }
        }

        self.pp_token_line_buffer.clear();
    }

    // precondition: pp_token_line_buffer contains all preprocessing tokens (excluding splices and final newline) from a single logical line
    fn convert_line_to_clexemes(&mut self) {
        // 1. check for preprocessing directive
        let non_whitespace = self.pp_token_line_buffer.iter().filter_map(|t| {
            if t.token != CPreprocessor::Whitespace {
                Some(t)
            } else {
                None
            }
        });

        if non_whitespace
            .take(2)
            .map(|x| x.token)
            .eq([CPreprocessor::Hash, CPreprocessor::Identifier])
        {
            let mut non_whitespace = std::mem::take(&mut self.pp_token_line_buffer)
                .into_iter()
                .filter(|t| t.token != CPreprocessor::Whitespace);
            non_whitespace.find(|t| t.token == CPreprocessor::Hash);
            let directive = non_whitespace
                .find(|t| t.token == CPreprocessor::Identifier)
                .unwrap(); // should never fail

            let first_non_wsp = non_whitespace.next();
            self.pp_token_line_buffer = non_whitespace.collect();
            if let Some(token) = first_non_wsp {
                self.pp_token_line_buffer.push_front(token);
            }

            self.preprocessor_directive(directive);
        } else {
        }
    }
}

impl TokenStream<CLexemes> for Preprocessor {
    fn eat(&mut self, lexeme: CLexemes) -> bool {
        todo!()
    }

    fn peek(&mut self) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn peekn(&mut self, n: usize) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn advance(&mut self) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn rollback(&mut self, target: usize) {
        todo!()
    }

    fn get_location(&self) -> usize {
        todo!()
    }
}
