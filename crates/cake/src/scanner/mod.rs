use std::borrow::Cow;
use std::collections::HashMap;
use std::collections::VecDeque;
use std::path::PathBuf;
use std::rc::Rc;

use self::lexeme_sets::c_lexemes::CLexemes;
use cake_lex::DFAScanner;
use cake_lex::LexemeSet;
use lexeme_sets::c_preprocessor::CPreprocessor;

// autogenerated lexeme sets
pub mod lexeme_sets;

// TODO: think about what interface should be for backtracking due to
// parsing troubles
pub trait TokenStream<T: LexemeSet> {
    fn eat(&mut self, lexeme: T) -> bool;
    fn peek(&mut self) -> Option<(T, &str, usize)>;
    fn peekn(&mut self, n: usize) -> Option<(T, &str, usize)>;
    fn advance(&mut self) -> Option<(T, &str, usize)>;

    fn rollback(&mut self, target: usize);
    fn get_location(&self) -> usize;
}

// TODO: processed token stream to implement preprocessor
// don't think you have to do a separate pass for preprocessing
const BUFFER_SIZE: usize = 10;
pub struct RawTokenStream<'a, T>
where
    T: LexemeSet,
{
    cursor: usize,
    scanner: DFAScanner,
    source: &'a [u8],

    buffer: VecDeque<(T, &'a str, usize)>,
}

impl<'a, T: LexemeSet> RawTokenStream<'a, T> {
    pub fn new(scanner: DFAScanner, source: &'a [u8]) -> RawTokenStream<'a, T> {
        let retval = RawTokenStream {
            cursor: 0,
            scanner,
            source,

            buffer: VecDeque::new(),
        };

        retval
    }

    fn refill_buffer(&mut self) {
        self.refill_buffer_to_size(BUFFER_SIZE);
    }

    fn refill_buffer_to_size(&mut self, size: usize) {
        while self.buffer.len() < size {
            let (lexeme, action, next_cursor) = self.scanner.next_word(self.source, self.cursor);

            if action == -1 {
                break;
            }
            // if action as u32 == CLexemes::Whitespace.to_id() {
            //     self.cursor = next_cursor;
            //     continue;
            // }
            let l = T::from_id(action as u32).expect("invalid action (is the scanner compatible?)");
            self.buffer.push_back((l, lexeme, self.cursor));
            self.cursor = next_cursor;
        }
    }
}

// TODO: optimize this
impl<'a, T> TokenStream<T> for RawTokenStream<'a, T>
where
    T: LexemeSet,
{
    fn eat(&mut self, expected_lexeme: T) -> bool {
        self.refill_buffer();
        let matched = match self.buffer.pop_front() {
            Some((lexeme, _, _)) if lexeme == expected_lexeme => true,
            _ => false,
        };

        matched
    }

    fn peek(&mut self) -> Option<(T, &str, usize)> {
        self.refill_buffer();
        self.buffer.front().copied()
    }

    fn advance(&mut self) -> Option<(T, &str, usize)> {
        self.refill_buffer();
        let old_memo = self.buffer.pop_front();
        old_memo
    }

    fn rollback(&mut self, target: usize) {
        self.cursor = target;
        self.buffer.clear();
    }

    fn get_location(&self) -> usize {
        self.cursor
    }

    fn peekn(&mut self, n: usize) -> Option<(T, &str, usize)> {
        self.refill_buffer_to_size(n + 1);
        self.buffer.get(n).copied()
    }
}

// specialized implementation for C lexemes
// implements preprocessing logic
pub(crate) struct CTokenStream {
    preprocess_scanner: DFAScanner,
    main_scanner: DFAScanner,

    sources_map: HashMap<PathBuf, SourceFile>,
    sources: Vec<Box<str>>, // Box<str> is preferable to avoid indirection, since no need to mutate source files (?)
    cursor_stack: Vec<SourceCursor>,

    buffer: VecDeque<(CLexemes, usize, usize, usize)>,
    macros: HashMap<String, PreprocessorMacro>, // TODO: add stack of cursors
                                                // to get "in file included from..." type error warnings
}

struct SourceFile {
    // header guard optimization - #pragma once
    header_guard: Option<String>,
    source_idx: usize,
}

#[derive(Debug, Clone)]
struct SourceCursor {
    filepath: PathBuf,
    file_idx: usize,
    cursor: usize,
    line: usize,
}

enum PreprocessorMacro {
    ObjectMacro { replacement: Vec<CPreprocessor> },
    FunctionMacro {},
}

impl CTokenStream {
    pub fn new(file: PathBuf, contents: String) -> Self {
        let preprocess_scanner = DFAScanner::new(CPreprocessor::load_table());
        let main_scanner = DFAScanner::new(CLexemes::load_table());
        let sources = vec![contents.into_boxed_str()];
        let mut sources_map = HashMap::new();
        sources_map.insert(
            file.clone(),
            SourceFile {
                header_guard: None,
                source_idx: 0,
            },
        );

        Self {
            preprocess_scanner,
            main_scanner,

            sources_map,
            sources,
            cursor_stack: vec![SourceCursor {
                filepath: file,
                file_idx: 0,
                cursor: 0,
                line: 1,
            }],

            buffer: VecDeque::with_capacity(BUFFER_SIZE),
            macros: HashMap::new(),
        }
    }

    fn get_current_src_str(&self) -> &str {
        self.sources[self.current_cursor().file_idx].as_ref()
    }

    fn current_cursor(&self) -> &SourceCursor {
        // invariant: cursor stack must never be fully empty until compiler is finished
        self.cursor_stack.last().unwrap()
    }

    // line-by-line processing could lead to super pathological cases (e.g. gigantic single line macros)
    // or if someone decides to put their entire source file in one big line
    // but this is much simpler
    fn process_line(&mut self) {
        let src_str = self.get_current_src_str();
        let mut remaining_src_str = &src_str[self.current_cursor().cursor..];
        let mut logical_line = if let Some(newline_pos) = remaining_src_str.find('\n') {
            let up_to_newline;
            (up_to_newline, remaining_src_str) = remaining_src_str.split_at(newline_pos);
            Cow::Borrowed(up_to_newline)
        } else {
            // final line should be empty
            // TODO: issue warning if not
            Cow::Borrowed(remaining_src_str)
        };

        while let Some('\\') = logical_line.chars().next_back() {
            if remaining_src_str.is_empty() {
                break;
            }
            let mut logical_line_string = logical_line.into_owned();
            logical_line_string.pop();
            logical_line = Cow::Owned(logical_line_string);
        }
    }
}

impl TokenStream<CLexemes> for CTokenStream {
    fn eat(&mut self, lexeme: CLexemes) -> bool {
        todo!()
    }

    fn peek(&mut self) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn peekn(&mut self, n: usize) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn advance(&mut self) -> Option<(CLexemes, &str, usize)> {
        todo!()
    }

    fn rollback(&mut self, target: usize) {
        todo!()
    }

    fn get_location(&self) -> usize {
        todo!()
    }
}
